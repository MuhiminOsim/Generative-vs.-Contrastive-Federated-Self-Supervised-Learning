# Centralized Contrastive (CenCon) Pre-training Configuration
# This is the non-federated baseline for comparison with FedConSwin

experiment_name: "cencon_pretrain"
ssl_method: "fedcon"  # Uses same contrastive method, but centralized
model_name: "swinv2_tiny_window8_256"

# Model params
embed_dim: 768
projection_dim: 128
projection_hidden_dim: 2048  # Hidden dimension for 2-layer MLP projection head
temperature: 0.1  # Contrastive temperature τ

# Training params (matching paper exactly)
num_epochs: 30  # Centralized training epochs (equivalent to 20 federated rounds × local epochs)
batch_size: 64  # Batch size
learning_rate: 1.0e-4  # AdamW learning rate
weight_decay: 0.05  # Weight decay
image_size: 256
num_workers: 4

# Data configuration (combines all client data)
clients_data:
  client_1:
    name: "kaggle"
    path: "chest_xray/train"  # Kaggle dataset path (5,216 images)
  client_2:
    name: "rsna"
    path: "RSNA/Training"  # RSNA images path (26,684 images)
    csv_path: "RSNA/stage2_train_metadata.csv"  # RSNA CSV path

# Checkpointing
save_every: 10  # Save checkpoint every N epochs
checkpoint_dir: "checkpoints"
output_dir: "checkpoints"
